{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "752c9d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Appending Rows: 100%|████████████████████████████████████████████████████| 10737418/10737418 [31:59<00:00, 5594.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "# Specify the path to the existing dataset\n",
    "existing_dataset_path = \"books.csv\"\n",
    "\n",
    "# Define the target file size in bytes (3 GB)\n",
    "target_file_size = 3 * 1024 * 1024 * 1024  # 3 GB\n",
    "\n",
    "# Estimate the size of each row in bytes (adjust this based on your data)\n",
    "# For simplicity, let's assume each row contributes around 300 bytes to the file size\n",
    "estimated_row_size = 300\n",
    "\n",
    "# Calculate the number of rows needed to reach the target file size\n",
    "rows_to_add = int(target_file_size // estimated_row_size)\n",
    "\n",
    "# Create a temporary file to store the new data\n",
    "temp_file_path = \"temp_dataset.csv\"\n",
    "\n",
    "# Open the existing dataset and create a new temporary file\n",
    "with open(existing_dataset_path, 'r') as existing_file, open(temp_file_path, 'w') as temp_file:\n",
    "    # Copy the header from the existing dataset to the temporary file\n",
    "    header = existing_file.readline()\n",
    "    temp_file.write(header)\n",
    "\n",
    "    # Iterate over the existing dataset and copy rows to the temporary file\n",
    "    for line in existing_file:\n",
    "        temp_file.write(line)\n",
    "\n",
    "    # Create a tqdm progress bar for appending new rows\n",
    "    progress_bar = tqdm(total=rows_to_add, desc=\"Appending Rows\")\n",
    "\n",
    "    # Generate and append new rows to the temporary file to reach the target size\n",
    "    for _ in range(rows_to_add):\n",
    "        row_id = ''.join(random.choice(string.ascii_letters) for _ in range(10))\n",
    "        data = ''.join(random.choice(string.ascii_letters) for _ in range(100))\n",
    "        new_row = f\"{row_id},{data}\\n\"\n",
    "        temp_file.write(new_row)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "os.replace(temp_file_path, existing_dataset_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5faca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\AppData\\Local\\Temp\\ipykernel_10396\\1290218973.py:5: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('books.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas took 83.32999444007874 seconds to read the file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "df = pd.read_csv('books.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Pandas took {execution_time} seconds to read the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1477154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\anaconda3\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:195: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask took 76.67320609092712 seconds to read the file.\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "df = dd.read_csv('books.csv')\n",
    "df = df.compute()\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Dask took {execution_time} seconds to read the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f4d36f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11737437 entries, 0 to 11737436\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   Book Title   object\n",
      " 1   Author Name  object\n",
      " 2   Runtime      object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.8 GB\n"
     ]
    }
   ],
   "source": [
    "data.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c03bf5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testutility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "################\n",
    "# File Reading #\n",
    "################\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7571a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: books\n",
    "file_name: books\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - book_title\n",
    "    - author_name\n",
    "    - runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d732f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file\n",
    "import testutility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00f4a3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data['inbound_delimiter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7350a9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'books',\n",
       " 'file_name': 'books',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['book_title', 'author_name', 'runtime']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54617532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\AppData\\Local\\Temp\\ipykernel_9808\\3258300403.py:3: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_sample = pd.read_csv(\"books.csv\",delimiter=',')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warrior Fae</td>\n",
       "      <td>Caroline Peckham, Susanne Valenti</td>\n",
       "      <td>29 hrs and 37 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Choose Your Enemies</td>\n",
       "      <td>Sandy Mitchell</td>\n",
       "      <td>10 hrs and 4 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Ritual</td>\n",
       "      <td>Shantel Tessier</td>\n",
       "      <td>16 hrs and 46 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reckless</td>\n",
       "      <td>Elsie Silver</td>\n",
       "      <td>9 hrs and 58 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Puppeteers</td>\n",
       "      <td>Jason Chaffetz</td>\n",
       "      <td>8 hrs and 49 mins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Book Title                        Author Name             Runtime\n",
       "0          Warrior Fae  Caroline Peckham, Susanne Valenti  29 hrs and 37 mins\n",
       "1  Choose Your Enemies                     Sandy Mitchell   10 hrs and 4 mins\n",
       "2           The Ritual                    Shantel Tessier  16 hrs and 46 mins\n",
       "3             Reckless                       Elsie Silver   9 hrs and 58 mins\n",
       "4       The Puppeteers                     Jason Chaffetz   8 hrs and 49 mins"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal reading process of the file\n",
    "import pandas as pd\n",
    "df_sample = pd.read_csv(\"books.csv\",delimiter=',')\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebbd2c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\AppData\\Local\\Temp\\ipykernel_9808\\56779893.py:5: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(source_file, delimiter=delimiter)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warrior Fae</td>\n",
       "      <td>Caroline Peckham, Susanne Valenti</td>\n",
       "      <td>29 hrs and 37 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Choose Your Enemies</td>\n",
       "      <td>Sandy Mitchell</td>\n",
       "      <td>10 hrs and 4 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Ritual</td>\n",
       "      <td>Shantel Tessier</td>\n",
       "      <td>16 hrs and 46 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reckless</td>\n",
       "      <td>Elsie Silver</td>\n",
       "      <td>9 hrs and 58 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Puppeteers</td>\n",
       "      <td>Jason Chaffetz</td>\n",
       "      <td>8 hrs and 49 mins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Book Title                        Author Name             Runtime\n",
       "0          Warrior Fae  Caroline Peckham, Susanne Valenti  29 hrs and 37 mins\n",
       "1  Choose Your Enemies                     Sandy Mitchell   10 hrs and 4 mins\n",
       "2           The Ritual                    Shantel Tessier  16 hrs and 46 mins\n",
       "3             Reckless                       Elsie Silver   9 hrs and 58 mins\n",
       "4       The Puppeteers                     Jason Chaffetz   8 hrs and 49 mins"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_type = config_data['file_type']\n",
    "source_file = \"./\" + config_data['file_name'] + f'.{file_type}'\n",
    "delimiter = config_data['inbound_delimiter']\n",
    "\n",
    "df = pd.read_csv(source_file, delimiter=delimiter)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ecdb5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.col_header_val(df,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0a0fc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['book_title', 'author_name', 'runtime'], dtype='object')\n",
      "columns of YAML are: ['book_title', 'author_name', 'runtime']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns of files are:\" ,df.columns)\n",
    "print(\"columns of YAML are:\" ,config_data['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abff0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n",
      "col validation passed\n"
     ]
    }
   ],
   "source": [
    "if util.col_header_val(df,config_data)==0:\n",
    "    print(\"validation failed\")\n",
    "    # write code to reject the file\n",
    "else:\n",
    "    print(\"col validation passed\")\n",
    "    # write the code to perform further action\n",
    "    # in the pipleine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44288ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating test file for this demo:\n",
    "testdata = {\n",
    "    'Book Title' : ['a','b','c','d','e'],\n",
    "    'Author Name' : ['a','b','c','d','e'],\n",
    "    'Runtime' : [34, 30, 16,33,22],\n",
    "}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(testdata, columns=['Book Title', 'Author Name','Runtime'])\n",
    "df.to_csv(\"test_data_ingestion.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6376946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Book Title': ['a', 'b', 'c', 'd', 'e'],\n",
       " 'Author Name': ['a', 'b', 'c', 'd', 'e'],\n",
       " 'Runtime': [34, 30, 16, 33, 22]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe54d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 11737437\n",
      "Total Columns: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the path to the dataset\n",
    "dataset_path = \"books.csv\"\n",
    "\n",
    "# Calculate the file size in bytes\n",
    "file_size_bytes = os.path.getsize(dataset_path)\n",
    "\n",
    "# Calculate the total number of rows and columns\n",
    "df = pd.read_csv(dataset_path)\n",
    "total_rows = len(df)\n",
    "total_columns = len(df.columns)\n",
    "\n",
    "# Convert file size to human-readable format (e.g., MB or GB)\n",
    "def convert_bytes_to_human_readable(bytes):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if bytes < 1024.0:\n",
    "            break\n",
    "        bytes /= 1024.0\n",
    "    return f\"{bytes:.2f} {unit}\"\n",
    "\n",
    "# Get the file size in a human-readable format\n",
    "file_size_readable = convert_bytes_to_human_readable(file_size_bytes)\n",
    "\n",
    "# Create a summary\n",
    "summary = {\n",
    "    \"Total Rows\": total_rows,\n",
    "    \"Total Columns\": total_columns,\n",
    "}\n",
    "\n",
    "# Print the summary\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff53b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
